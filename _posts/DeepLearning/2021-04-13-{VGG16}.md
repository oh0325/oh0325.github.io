---
layout: single
title: 'VGG modeling'
categories:
  - DeepLearning
tags:
  - CNN, DeepLearning
comments: true  
classes: wide
toc: false
---

# VGG implementation

딥러닝 공부있는데 implement 부분에 있어 약하다고 생각해서  
pytorch로 모델링 공부를 해보겠습니다.  


model configuration   
![VGG_config1](../../assets/images/VGG/vgg_configure.png)
depth에 따라 model를 구분 지었습니다.  

저는 19개의 layer를 쌓은 vgg19 모델을 구현해 보겠습니다.  




model의 figure는 아래와 같습니다.  
model Aritecture    
![VGG_config2](../../assets/images/VGG/vgg_configure2.png)  



### Chek list   
- Input image size -> random crop 된 224x224 RGB imgae  
- Activation func  -> ReLU activation
- Nomalization     -> LRN
- Pooling          -> max pooling
- Batch size       -> 256
- Optimizer        -> MSGD , momentum 0.9
- Weight decay     -> 5.10^-4
- Loss function    -> Cross Entropy
- Drop out         -> Fully connected layer 0.5
- Learning rate    -> 0.01  ... validation accuracy가 증가 안하면 10으로 나눠준다.
 총 3번 감소했으며, 74 epoch에서 멈췄다. 
- initialization   -> VGG11 에서 학습한 weight를 사용했으나, 나중에는 xiveir weight를 사용.

input image로는 224x224 size의 RGB imgae를 사용합니다.
기존의 image를 crop를 해서 사용합니다.

![VGG_crop](../../assets/images/VGG/vgg_crop.png)

